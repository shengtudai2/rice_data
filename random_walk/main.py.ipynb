{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 共表达随机游走-基因邻近集合"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "os.chdir(\"D:/code/python/ClusterGAN/random_walk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.a 读入共表达网路，选取最大联通子图\n",
    "包含20859个节点，232945条边"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/int_net.csv\", index_col=0)\n",
    "edges = list(zip(df.iloc[:,0], df.iloc[:,1], [{'p': df.iloc[i, 2]} for i in range(len(df))]))\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "sg = max(nx.connected_components(G), key=len)\n",
    "sub_G = G.subgraph(sg)\n",
    "df_subg = pd.DataFrame(sub_G.edges())\n",
    "df_subg.columns = ['g1', 'g2']\n",
    "# df_subg.to_csv(\"data/max_connect_net.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.b 节点名称映射"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nline = \"\"\\nfor k, v in map_dict.items():\\n    line += k + \\',\\' + v + \\'\\n\\'\\nfp.write(line)\\nfp.close()\\n'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = list(map(lambda x: x.strip('\\n'), open(\"data/allTFs.txt\", 'r').readlines()))\n",
    "# net = pd.read_csv(\"data/max_connect_net.csv\", index_col=0, header=0)\n",
    "net = df_subg\n",
    "net_val = net.values\n",
    "nodes = np.unique(net_val.flatten())\n",
    "tf_count = 0\n",
    "tg_count = 0\n",
    "map_dict = dict()\n",
    "# fp = open(\"data/map_file.txt\", \"w\", encoding=\"utf8\")\n",
    "for _ in nodes:\n",
    "    if _ in tfs:\n",
    "        tf_count += 1\n",
    "        tf_name = f\"F{tf_count}\"\n",
    "        map_dict[_] = tf_name\n",
    "    else:\n",
    "        tg_count += 1\n",
    "        tg_name = f\"G{tg_count}\"\n",
    "        map_dict[_] = tg_name\n",
    "'''\n",
    "line = \"\"\n",
    "for k, v in map_dict.items():\n",
    "    line += k + ',' + v + '\\n'\n",
    "fp.write(line)\n",
    "fp.close()\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 网络游走权重"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def node_neib_p(G:nx.Graph):\n",
    "    p_dict = dict()\n",
    "    for node in list(G.nodes()):\n",
    "        curr_node_nbrs = list(G.neighbors(node))\n",
    "        p = [abs(G[node][i]['p']) for i in curr_node_nbrs]\n",
    "        p = list(map(lambda x: x / sum(p), p))\n",
    "        p_dict[node] = p\n",
    "    return p_dict\n",
    "\n",
    "p_dict = node_neib_p(G)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 随机游走找近邻-算法实现\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import random\n",
    "def deep_walk(G:nx.Graph, snode:str):\n",
    "    tfs = list()\n",
    "    tgs = list()\n",
    "    walk_seq = snode\n",
    "    while len(tfs)<10 or len(tgs) < 90:\n",
    "        rnd = random.random()\n",
    "        if rnd <= 0.5:\n",
    "            # walk_seq.append(snode) # 重启\n",
    "            curr_node = snode\n",
    "        else:\n",
    "            curr_node = walk_seq\n",
    "        curr_node_nbrs = list(G.neighbors(curr_node))\n",
    "        #p = [abs(G[curr_node][i]['p']) for i in curr_node_nbrs]\n",
    "        #p = list(map(lambda x: x/sum(p), p))\n",
    "        next_node = np.random.choice(curr_node_nbrs, p = p_dict[curr_node])\n",
    "        if next_node.startswith('G'):\n",
    "            tgs.append(next_node)\n",
    "        else:\n",
    "            tfs.append(next_node)\n",
    "        walk_seq = next_node\n",
    "    return tfs[0:10], tgs[0:90]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def node2Vector(node:str, G:nx.Graph):\n",
    "    fp = open(f\"ndvct/{node}.txt\", \"w\")\n",
    "    TFS = []\n",
    "    TGS = []\n",
    "    for step in range(10):\n",
    "        tfs, tgs = deep_walk(G, node)\n",
    "        TFS.extend(tfs)\n",
    "        TGS.extend(tgs)\n",
    "    C_TF = Counter(TFS)\n",
    "    C_TG = Counter(TGS)\n",
    "    maxTFs = sorted(C_TF.keys(), key=lambda x:C_TF[x], reverse=True)[0:2]\n",
    "    maxTGs = sorted(C_TG.keys(), key=lambda x:C_TG[x], reverse=True)[0:8]\n",
    "    fp.write(\",\".join(maxTFs) + \",\" + \",\".join(maxTGs))\n",
    "    fp.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def pp(nodes:list):\n",
    "        for n in nodes:\n",
    "            node2Vector(n, G)\n",
    "    n = 2858\n",
    "    nodes = list(G.nodes())\n",
    "    output=[nodes[i:i + n] for i in range(0, len(nodes), n)]\n",
    "    cpu_work_num = len(output)\n",
    "    with multiprocessing.Pool(cpu_work_num) as p:\n",
    "        p.map(pp, output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytoch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}